"""
PDF Processing Service
PDF dosyalarƒ±nƒ± i≈üleme ve chunk'lara b√∂lme servisi
"""

import os
import json
import uuid
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import logging

# PDF processing libraries
try:
    import PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    try:
        import pdfplumber
        PyPDF2 = None
        PDF_AVAILABLE = True
    except ImportError:
        PDF_AVAILABLE = False

from app.core.config import settings
from app.core.database import get_db
from app.models.pdf_document import PDFDocument, PDFChunk
from app.schemas.pdf_document import PDFDocumentCreate, PDFChunkCreate
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


class PDFProcessor:
    """PDF i≈üleme servisi"""
    
    def __init__(self):
        self.chunk_size = 2000  # Karakterde chunk boyutu (artƒ±rƒ±ldƒ±)
        self.chunk_overlap = 300  # Overlap miktarƒ± (artƒ±rƒ±ldƒ±)
        self.upload_dir = "app/uploads/pdfs/"
        
        # Upload dizinini olu≈ütur
        os.makedirs(self.upload_dir, exist_ok=True)
    
    async def save_uploaded_file(self, file_content: bytes, original_filename: str) -> str:
        """Y√ºklenen dosyayƒ± kaydet"""
        try:
            # Unique filename olu≈ütur
            file_extension = os.path.splitext(original_filename)[1]
            unique_filename = f"{uuid.uuid4()}{file_extension}"
            file_path = os.path.join(self.upload_dir, unique_filename)
            
            # Dosyayƒ± kaydet
            with open(file_path, "wb") as f:
                f.write(file_content)
            
            logger.info(f"üìÅ PDF dosyasƒ± kaydedildi: {file_path}")
            return file_path
            
        except Exception as e:
            logger.error(f"‚ùå Dosya kaydetme hatasƒ±: {e}")
            raise
    
    async def extract_text_from_pdf(self, file_path: str) -> str:
        """PDF'den metin √ßƒ±kar"""
        if not PDF_AVAILABLE:
            raise ValueError("PDF i≈üleme k√ºt√ºphanesi kurulu deƒüil")
        
        try:
            text = ""
            
            if PyPDF2:
                # PyPDF2 kullan
                with open(file_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    for page_num, page in enumerate(pdf_reader.pages):
                        page_text = page.extract_text()
                        if page_text:
                            text += f"\n[Sayfa {page_num + 1}]\n{page_text}\n"
            else:
                # pdfplumber kullan
                import pdfplumber
                with pdfplumber.open(file_path) as pdf:
                    for page_num, page in enumerate(pdf.pages):
                        page_text = page.extract_text()
                        if page_text:
                            text += f"\n[Sayfa {page_num + 1}]\n{page_text}\n"
            
            logger.info(f"üìÑ PDF metin √ßƒ±karƒ±ldƒ±: {len(text)} karakter")
            return text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå PDF metin √ßƒ±karma hatasƒ±: {e}")
            raise
    
    def _create_smart_chunk(self, text: str, page_num: int) -> tuple[str, str]:
        """Akƒ±llƒ± chunk olu≈ütur - c√ºmle sƒ±nƒ±rlarƒ±nƒ± ve anlam b√ºt√ºnl√ºƒü√ºn√º korur"""
        
        # √ñnce ideal chunk boyutunu al
        target_chunk = text[:self.chunk_size]
        
        # 1. Paragraf sƒ±nƒ±rƒ±nda kes (en iyi)
        paragraph_breaks = [i for i, char in enumerate(target_chunk) if char == '\n' and i > self.chunk_size - 400]
        if paragraph_breaks:
            cut_point = max(paragraph_breaks)
            chunk_text = text[:cut_point]
            remaining_text = text[cut_point - self.chunk_overlap:]
            return chunk_text.strip(), remaining_text.strip()
        
        # 2. C√ºmle sonunda kes (iyi)
        sentence_ends = [i for i, char in enumerate(target_chunk) if char in '.!?' and i > self.chunk_size - 300]
        if sentence_ends:
            cut_point = max(sentence_ends) + 1
            chunk_text = text[:cut_point]
            remaining_text = text[cut_point - self.chunk_overlap:]
            return chunk_text.strip(), remaining_text.strip()
        
        # 3. Kelime sƒ±nƒ±rƒ±nda kes (orta)
        words = target_chunk.split()
        if len(words) > 10:
            # Son 10 kelimeyi kontrol et
            word_positions = []
            current_pos = 0
            for i, word in enumerate(words[:-10]):
                current_pos += len(word) + 1  # +1 for space
                word_positions.append(current_pos)
            
            if word_positions:
                cut_point = word_positions[-1]
                chunk_text = text[:cut_point]
                remaining_text = text[cut_point - self.chunk_overlap:]
                return chunk_text.strip(), remaining_text.strip()
        
        # 4. Son √ßare: sabit boyutta kes
        chunk_text = text[:self.chunk_size]
        remaining_text = text[self.chunk_size - self.chunk_overlap:]
        return chunk_text.strip(), remaining_text.strip()
    
    async def create_chunks(self, text: str, pdf_document_id: int) -> List[PDFChunkCreate]:
        """Metni akƒ±llƒ± chunk'lara b√∂l - sayfa sƒ±nƒ±rlarƒ± ve c√ºmle b√ºt√ºnl√ºƒü√º korunur"""
        try:
            chunks = []
            chunk_index = 0
            
            # Sayfa bazlƒ± b√∂lme
            pages = text.split('[Sayfa ')
            current_text = ""
            current_page = 1
            
            for page_section in pages[1:]:  # ƒ∞lk bo≈ü elementi atla
                # Sayfa numarasƒ±nƒ± √ßƒ±kar
                if ']' in page_section:
                    page_content = page_section.split(']', 1)[1]
                    page_num = int(page_section.split(']')[0])
                else:
                    page_content = page_section
                    page_num = current_page
                
                # Sayfa i√ßeriƒüini temizle
                page_content = page_content.strip()
                if not page_content:
                    continue
                    
                current_text += f" {page_content}" if current_text else page_content
                
                # Chunk boyutu kontrol et
                while len(current_text) >= self.chunk_size:
                    chunk_text, remaining_text = self._create_smart_chunk(current_text, page_num)
                    
                    # Chunk olu≈ütur
                    chunk = PDFChunkCreate(
                        pdf_document_id=pdf_document_id,
                        chunk_index=chunk_index,
                        content=chunk_text.strip(),
                        page_number=page_num
                    )
                    chunks.append(chunk)
                    chunk_index += 1
                    
                    current_text = remaining_text
                
                current_page = page_num + 1
            
            # Kalan metni son chunk olarak ekle
            if current_text.strip():
                chunk = PDFChunkCreate(
                    pdf_document_id=pdf_document_id,
                    chunk_index=chunk_index,
                    content=current_text.strip(),
                    page_number=current_page - 1
                )
                chunks.append(chunk)
            
            logger.info(f"üìù {len(chunks)} chunk olu≈üturuldu")
            return chunks
            
        except Exception as e:
            logger.error(f"‚ùå Chunk olu≈üturma hatasƒ±: {e}")
            raise
    
    async def process_pdf(self, pdf_document_id: int, file_path: str, db: Session) -> Dict[str, Any]:
        """PDF'i tamamen i≈üle"""
        start_time = datetime.now()
        
        try:
            # PDF dok√ºmanƒ±nƒ± al
            pdf_doc = db.query(PDFDocument).filter(PDFDocument.id == pdf_document_id).first()
            if not pdf_doc:
                raise ValueError(f"PDF dok√ºman bulunamadƒ±: {pdf_document_id}")
            
            # Metin √ßƒ±kar
            text = await self.extract_text_from_pdf(file_path)
            
            # PDF dok√ºmanƒ±nƒ± g√ºncelle
            pdf_doc.content_text = text
            pdf_doc.is_processed = True
            pdf_doc.processed_at = datetime.now()
            db.commit()
            
            # Chunk'larƒ± olu≈ütur
            chunks_data = await self.create_chunks(text, pdf_document_id)
            
            # Chunk'larƒ± veritabanƒ±na kaydet
            saved_chunks = 0
            for chunk_data in chunks_data:
                chunk = PDFChunk(
                    pdf_document_id=chunk_data.pdf_document_id,
                    chunk_index=chunk_data.chunk_index,
                    content=chunk_data.content,
                    page_number=chunk_data.page_number
                )
                db.add(chunk)
                saved_chunks += 1
            
            # Chunk sayƒ±sƒ±nƒ± g√ºncelle
            pdf_doc.chunk_count = saved_chunks
            db.commit()
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                "success": True,
                "message": f"PDF ba≈üarƒ±yla i≈ülendi",
                "chunks_created": saved_chunks,
                "processing_time": processing_time,
                "text_length": len(text)
            }
            
            logger.info(f"‚úÖ PDF i≈üleme tamamlandƒ±: {pdf_document_id} - {saved_chunks} chunk")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå PDF i≈üleme hatasƒ±: {e}")
            # Hata durumunda PDF'i i≈ülenmemi≈ü olarak i≈üaretle
            try:
                pdf_doc = db.query(PDFDocument).filter(PDFDocument.id == pdf_document_id).first()
                if pdf_doc:
                    pdf_doc.is_processed = False
                    db.commit()
            except:
                pass
            
            raise
    
    async def get_categories(self, db: Session = None) -> List[str]:
        """Mevcut kategorileri al"""
        try:
            if db is None:
                db = next(get_db())
                should_close = True
            else:
                should_close = False
                
            categories = db.query(PDFDocument.category).distinct().all()
            return [cat[0] for cat in categories if cat[0]]
        except Exception as e:
            logger.error(f"‚ùå Kategori alma hatasƒ±: {e}")
            return []
        finally:
            if should_close and db:
                db.close()
    
    async def get_pdf_stats(self, user_id: int, db: Session = None) -> Dict[str, Any]:
        """PDF istatistikleri al"""
        try:
            if db is None:
                db = next(get_db())
                should_close = True
            else:
                should_close = False
            
            # Toplam dok√ºmanblar
            total_docs = db.query(PDFDocument).filter(PDFDocument.user_id == user_id).count()
            
            # Toplam chunk'lar
            total_chunks = db.query(PDFChunk).join(PDFDocument).filter(
                PDFDocument.user_id == user_id
            ).count()
            
            # Embedded chunk'lar
            embedded_chunks = db.query(PDFChunk).join(PDFDocument).filter(
                PDFDocument.user_id == user_id,
                PDFChunk.is_embedded == True
            ).count()
            
            # Kategoriler
            categories = db.query(PDFDocument.category).filter(
                PDFDocument.user_id == user_id
            ).distinct().all()
            
            # Toplam boyut
            total_size = db.query(PDFDocument.file_size).filter(
                PDFDocument.user_id == user_id
            ).all()
            total_size_bytes = sum([size[0] for size in total_size])
            total_size_mb = total_size_bytes / (1024 * 1024)
            
            # ƒ∞≈üleme durumu
            processed_docs = db.query(PDFDocument).filter(
                PDFDocument.user_id == user_id,
                PDFDocument.is_processed == True
            ).count()
            
            return {
                "total_documents": total_docs,
                "total_chunks": total_chunks,
                "embedded_chunks": embedded_chunks,
                "categories": [cat[0] for cat in categories],
                "total_size_mb": round(total_size_mb, 2),
                "processing_status": {
                    "processed": processed_docs,
                    "pending": total_docs - processed_docs,
                    "embedding_progress": f"{embedded_chunks}/{total_chunks}" if total_chunks > 0 else "0/0"
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå PDF istatistik hatasƒ±: {e}")
            return {}
        finally:
            if should_close and db:
                db.close()


# Global PDF Processor instance
pdf_processor = PDFProcessor()